<!DOCTYPE HTML>
<html>
    <head>
        <title>Publications</title>
        <style>
            body {
                font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
                margin: 0;
                padding: 0;
                background-color: #f0f2f5;
                color: #333;
            }
            .container {
                max-width: 960px;
                margin: 20px auto;
                padding: 20px;
                background: #ffffff;
                border-radius: 8px;
                box-shadow: 0 2px 5px rgba(0,0,0,0.1);
            }
            h2.major {
                color: #34495e;
                font-size: 28px;
                text-align: center;
                margin-bottom: 30px;
            }
            .publications-section {
                margin-bottom: 40px;
            }
            .category-title {
                font-size: 22px;
                background-color: #3498db;
                color: #ffffff;
                padding: 10px 15px;
                margin: 10px 0 20px;
                border-radius: 5px;
                box-shadow: 0 2px 4px rgba(0,0,0,0.2);
                display: inline-block;
            }
            .year-section {
                padding-left: 20px;
                border-left: 4px solid #3498db;
                margin-bottom: 20px;
            }
            h3.year {
                font-size: 20px;
                color: #2c3e50;
                margin: 10px 0 15px;
                padding-bottom: 5px;
                border-bottom: 2px solid #3498db;
            }
            p, .category {
                line-height: 1.6;
            }
            a {
                color: #2980b9;
                text-decoration: none;
            }
            a:hover {
                text-decoration: underline;
            }
            footer {
                text-align: center;
                padding: 20px;
                margin-top: 20px;
                background-color: #2c3e50;
                color: #fff;
                border-radius: 0 0 8px 8px;
            }

            .publication-type, .venue-name {
                font-weight: bold;
                color: #F4593D; /* Change the color as per your design preference */
            }
            
            /* Additional styling to enhance appearance */
            .publication p {
                background-color: #f9f9f9;
                padding: 10px;
                border-left: 4px solid #3498db;
                margin-bottom: 15px;
            }
            
            .publication p:hover {
                background-color: #e9e9e9;
            }

            .pub-title {
                color: #5F0BF2
            }

            
        </style>
    </head>
    <body>
    
        <div class="container">
            <h2 class="major">Publications</h2>
        
        <span class="image main">
            <img src="images/thesis.png" alt=""/>
        </span>

    <div class="publications-section">
        <div class="category-title">Papers</div>
        <div class="year-section">
            <h3 class="year">2025</h3>
            
            <p>
                    <b class="pub-title">SafeChat: A Framework for Building Trustworthy Collaborative Assistants and a Case Study of its Usefulness</b>
                    <br><b>Authors:</b> Biplav Srivastava, Kausik Lakkaraju, Nitin Gupta, Vansh Nagpal, Bharath C Muppasani, Sara E Jones
                    <br><b>Summary:</b>
                    <br>
                    Modern chatbots powered by large language models (LLMs) are widely accessible but face issues like lack of transparency, 
                    safety concerns, and complex development. These limitations make them unsuitable for sensitive areas like elections or healthcare. 
                    To address this, we introduce SafeChat, a flexible and trustworthy chatbot framework built on Rasa. 
                    It supports source-traceable answers, deflects unsafe queries, summarizes responses, and enables rapid development through a CSV-driven workflow. 
                    We used it to build ElectionBot-SC and other safe assistants. 
                    Project link: <a href="https://github.com/ai4society/trustworthy-chatbot">https://github.com/ai4society/trustworthy-chatbot</a>
                    <br><b>Publication Type:</b> <span class="publication-type">Unpublished Manuscript</span>
                    <br><a href="https://arxiv.org/pdf/2504.07995"><b>Paper</b></a>
                    |<a href="../bibs/2025_safechat.txt"><b>Bibtex</b></a>
            </p>
            <p>
                    <b class="pub-title">On Creating a Causally Grounded Usable Rating Method for Assessing the Robustness of Foundation Models Supporting Time Series</b>
                    <br><b>Authors:</b> Kausik Lakkaraju, Rachneet Kaur, Parisa Zehtabi, Sunandita Patra, Siva Likitha Valluru, Zhen Zeng, Biplav Srivastava, Marco Valtorta
                    <br><b>Summary:</b>
                    <br>Foundation Models have improved time-series forecasting but remain sensitive to input noise. 
                    We propose a causal rating framework to evaluate their robustness using stock prediction as a 
                    case study. Our findings show that multi-modal and task-specific foundation models are both more accurate and more robust. 
                    Our user study confirmed that our ratings help users better compare model reliability.
                    <br><b>Publication Type:</b> <span class="publication-type">Unpublished Manuscript</span>
                    <br><a href="https://arxiv.org/pdf/2502.12226?"><b>Paper</b></a>
                    |<a href="../bibs/2025_tsfm.txt"><b>Bibtex</b></a>
            </p>
            <p>
                    <b class="pub-title">ElectionBot-SC: A Tool to Understand and Compare Chatbot Behavior for Safe Election Information in South Carolina</b>
                    <br><b>Authors:</b>Bharath Muppasani, Kausik Lakkaraju, Nitin Gupta, Vansh Nagpal, Sara Jones, Biplav Srivastava
                    <br><b>Summary:</b>
                    <br><p> With the 2024 elections underway, getting trustworthy election info is critical. 
                        We present ElectionBot-SC, a chatbot that provides verified election guidance from official and 
                        nonprofit sources. It supports multiple engines—rule-based, search-based, and LLM—to answer 
                        queries while showing where the information comes from. It's currently being tested at a 
                        South Carolina university to help students and staff, including first-time voters.
                        <strong>Demo video:</strong> <a href="https://shorturl.at/1A7cc">https://shorturl.at/1A7cc</a>
                    </p>
                    <br><b>Publication Type:</b> <span class="publication-type">Unpublished Manuscript</span>
                    <br><a href="https://ai4society.github.io/publications/papers_local/AAAI_25_SafeChat_Demo.pdf"><b>Paper</b></a>
                    |<a href="../bibs/2025_scbot.txt"><b>Bibtex</b></a>
            </p>
            </div>
            <div class="year-section">
            <h3 class="year">2024</h3>
            <p>
                    <b class="pub-title">A Novel Approach to Balance Convenience and Nutrition in Meals With Long-Term Group Recommendations and Reasoning on Multimodal Recipes and its Implementation in BEACON</b>
                    <br><b>Authors:</b>Vansh Nagpal, Siva Likitha Valluru, Kausik Lakkaraju, Nitin Gupta, Zach Abdulrahman, Andrew Davison, Biplav Srivastava
                    <br><b>Summary:</b>
                    <br>Meal choices often involve trade-offs between health and convenience. We propose a data-driven system 
                    that recommends customizable meals over time, balancing user preferences with nutrition and 
                    preparation details. Key contributions include new meal quality measures, recipe conversion 
                    to a rich multimodal format (R3), learning methods using contextual bandits, and a working 
                    prototype called BEACON.
                    <br><b>Publication Type:</b> <span class="publication-type">Unpublished Manuscript</span>
                    <br><a href="https://arxiv.org/abs/2412.17910"><b>Paper</b></a>
                    |<a href="../bibs/2024_beacon2.txt"><b>Bibtex</b></a>
            </p>
            <p>
                    <b class="pub-title">BEACON: Balancing Convenience and Nutrition in Meals With Long-Term Group Recommendations and Reasoning on Multimodal Recipes</b>
                    <br><b>Authors:</b> Vansh Nagpal, Siva Likitha Valluru, Kausik Lakkaraju, Biplav Srivastava
                    <br><b>Summary:</b>
                    <br>Choosing what to eat often means balancing health and convenience. 
                    In this work, we tackle the meal recommendation problem by designing a system 
                    that considers both nutrition and practicality, while also understanding ingredients 
                    and cooking steps. We introduce a new way to rate meals, convert recipes into a rich format, 
                    and use learning methods that adapt to user context, all showing early promise.
                    <br><b>Publication Type:</b> <span class="publication-type">Unpublished Manuscript</span>
                    <br><a href="https://arxiv.org/abs/2406.13714"><b>Paper</b></a>
                    |<a href="../bibs/2024_beacon.txt"><b>Bibtex</b></a>
            </p>
            <p>
                    <b class="pub-title">Rating Multi-Modal Time-Series Forecasting Models (MM-TSFM) for Robustness Through a Causal Lens</b>
                    <br><b>Authors:</b> Kausik Lakkaraju, Rachneet Kaur, Zhen Zeng, Parisa Zehtabi, Sunandita Patra, Biplav Srivastava, Marco Valtorta
                    <br><b>Summary:</b>
                    <br>AI forecasting models can behave unpredictably when inputs change slightly, which is risky in finance. 
                    We study models that use both numbers and images (multi-modal) and propose a causal rating method to test how robust they are. 
                    Across a large experiment, we find that multi-modal models (ViT-num-spec models) are not just more accurate, but also more reliable, making them a 
                    better fit for decision-making under uncertainty.
                    <br><b>Publication Type:</b> <span class="publication-type">Unpublished Manuscript</span>
                    <!-- <br><b>Venue:</b> <span class="venue-name">IEEE Transactions on Technology and Society</span> -->
                    <br><a href="https://arxiv.org/abs/2406.12908"><b>Paper</b></a>
                    |<a href="../bibs/2024_mmtsfm.txt"><b>Bibtex</b></a>
            </p>
            <p>
                    <b class="pub-title">Rating Sentiment Analysis Systems for Bias Through a Causal Lens</b>
                    <br><b>Authors:</b> Kausik Lakkaraju, Biplav Srivastava, Marco Valtorta
                    <br><b>Summary:</b>
                    <br>Sentiment Analysis Systems (SASs) analyze text emotions but can inaccurately change ratings over minor input variations, 
                    showing potential bias towards attributes like gender or race. 
                    We propose a method to evaluate and rate SASs on their sensitivity to these 
                    attributes, aiming to help choose more fair and reliable systems and reduce bias-induced hate speech online.
                    <br><b>Publication Type:</b> <span class="publication-type">Journal</span>
                    <br><b>Venue:</b> <span class="venue-name">IEEE Transactions on Technology and Society</span>
                    <br><a href="https://ieeexplore.ieee.org/abstract/document/10466637"><b>Paper</b></a>
                    |<a href="../bibs/2024_ieee_tts.txt"><b>Bibtex</b></a>
            </p>
            <p>
                <b class="pub-title">Trust and ethical considerations in a multi-modal, explainable AI-driven chatbot tutoring system: The case of collaboratively solving Rubik's Cube</b>
                <br><b>Authors:</b> Kausik Lakkaraju, Vedant Khandelwal, Biplav Srivastava, Forest Agostinelli, Hengtao Tang, Prathamjeet Singh, Dezhi Wu, Matt Irvin, Ashish Kundu
                <br><b>Summary:</b>
                <br>AI can revolutionize education by analyzing vast data on student learning but faces unresolved ethical concerns, 
                such as data privacy and fairness, especially in high school settings. This paper introduces the ALLURE chatbot, 
                a platform designed to address these ethical issues, allowing students to collaboratively solve the Rubik's cube with AI. 
                Key features include prioritizing informed consent for data use and ensuring safe interaction and language use to protect students. 
                It also focuses on preventing information leakage between user groups as the system learns and improves.
                <br><b>Publication Type:</b> <span class="publication-type">Workshop</span>
                <br><b>Venue:</b> <span class="venue-name">ICML Workshop on What’s left to TEACH (Trustworthy, Enhanced, Adaptable, Capable and Human-centric) chatbots?</span>
                <br><a href="https://arxiv.org/abs/2402.01760"><b>Paper</b></a>
                |<a href="../bibs/2023_teach.txt"><b>Bibtex</b></a>
            </p>
            <p>
                <b class="pub-title">Advances in Automatically Rating the Trustworthiness of Text Processing Services</b>
                <br><b>Authors:</b> Biplav Srivastava, Kausik Lakkaraju, Mariana Bernagozzi, Marco Valtorta
                <br><b>Summary:</b>
                <br>In this symposium paper, we talked about the previous approaches that were used to rate the trustworthiness of AI systems and we also 
                outlined the challenges and vision for a principled, causality-based, and multi-modal rating methodologies. 
                <br><b>Publication Type:</b> <span class="publication-type">Journal, Symposium</span>
                <br><b>Venue:</b> <span class="venue-name">AI and Ethics Journal; AAAI Spring Symposium</span>
                <br><a href="https://link.springer.com/article/10.1007/s43681-023-00391-5"><b>Paper</b></a>
                |<a href="../bibs/2023_sympo.txt"><b>Bibtex</b></a>
            </p>
        </div>
        <div class="year-section">
            <h3 class="year">2023</h3>
            <p>
                <b class="pub-title">LLMs for Financial Advisement: A Fairness and Efficacy Study in Personal Decision Making</b>
                <br><b>Authors:</b> Kausik Lakkaraju, Sara E Jones, Sai Krishna Revanth Vuruma, Vishal Pallagani, Bharath C Muppasani, Biplav Srivastava
                <br><b>Summary:</b>
                <br>
                We compared ChatGPT and Bard, LLM-based chatbots, with SafeFinance, a rule-based chatbot, 
                in the personal finance domain. Our findings reveal that ChatGPT and Bard often provide inconsistent and 
                unreliable financial advice, while SafeFinance, though simpler, 
                offers dependable and accurate information. This study highlights the current limitations of 
                LLM-based chatbots in handling financial advisement tasks effectively.
                <br><b>Publication Type:</b> <span class="publication-type">Conference</span>
                <br><b>Venue:</b> <span class="venue-name">Proceedings of the Fourth ACM International Conference on AI in Finance</span>
                <br><a href="https://dl.acm.org/doi/pdf/10.1145/3604237.3626867"><b>Paper</b></a>
                |<a href="../bibs/2023_icaif.txt"><b>Bibtex</b></a>
            </p>

            <p>
                <b class="pub-title">The Effect of Human v/s Synthetic Test Data and Round-tripping on Assessment of Sentiment Analysis Systems for Bias</b>
                <br><b>Authors:</b> Kausik Lakkaraju, Aniket Gupta, Biplav Srivastava, Marco Valtorta, Dezhi Wu
                <br><b>Summary:</b>
                <br>
                Sentiment Analysis Systems (SASs), AI tools that analyze text sentiment, can show unstable and biased behavior, raising trust issues. 
                A new method rates these systems for bias using synthetic data. We enhanced this by using real chatbot conversations and a technique 
                that translates data through another language and back. 
                This revealed more bias in real compared to synthetic data, but translating through Spanish or Danish reduced bias significantly in real data. 
                <br><b>Publication Type:</b> <span class="publication-type">Conference</span>
                <br><b>Venue:</b> <span class="venue-name">The Fifth IEEE International Conference on Trust, Privacy and Security in Intelligent Systems, and Applications</span>
                <br><a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10431645"><b>Paper</b></a>
                |<a href="../bibs/2023_ieee_tps.txt"><b>Bibtex</b></a>
            </p>

            <p>
                <b class="pub-title">Evaluating Chatbots to Promote Users' Trust -- Practices and Open Problems</b>
                <br><b>Authors:</b> Biplav Srivastava, Kausik Lakkaraju, Tarmo Koppel, Vignesh Narayanan, Ashish Kundu, Sachindra Joshi
                <br><b>Summary:</b>
                <br>Chatbots have gained widespread attention, especially with the advent of LLM-based systems like ChatGPT and Bard. 
                As they become integral in business for engaging with customers, suppliers, and employees, ensuring their reliability 
                through thorough testing is crucial. This paper examines how chatbots are currently tested, 
                highlights the challenges in building user trust, and proposes directions for future research and development.
                <br><b>Publication Type:</b> <span class="publication-type">Unpublished Manuscript</span>
                <!-- <br><b>Venue:</b> <span class="venue-name">The Fifth IEEE International Conference on Trust, Privacy and Security in Intelligent Systems, and Applications</span> -->            
                <br><a href="https://arxiv.org/abs/2309.05680"><b>Paper</b></a> 
                |<a href="../bibs/2023_eval_chatbots.txt"><b>Bibtex</b></a>
            </p>

            <p>
                <b class="pub-title">Can LLMs be Good Financial Advisors?: An Initial Study in Personal Decision Making for Optimized Outcomes</b>
                <br><b>Authors:</b> Kausik Lakkaraju, Sai Krishna Revanth Vuruma, Vishal Pallagani, Bharath Muppasani, Biplav Srivastava
                <br><b>Summary:</b>
                <br>
                We tested advanced chatbots like ChatGPT and Bard on personal finance advice, using 13 questions in different 
                languages and dialects. Although the chatbots' answers sounded good, 
                we found they often lacked accuracy and reliability in providing financial information.
                <br><b>Publication Type:</b> <span class="publication-type">Workshop</span>
                <br><b>Venue:</b> <span class="venue-name">ICAPS Workshop on Planning for Financial Services</span>
                <br><a href="https://icaps23.icaps-conference.org/papers/finplan/Proceedings_FinPlan2023.pdf#page=55"><b>Paper</b></a>
                |<a href="../bibs/2023_finplan.txt"><b>Bibtex</b></a>
            </p>

            <p>
                <b class="pub-title">On Safe and Usable Chatbots for Promoting Voter Participation</b>.
                <br><b>Authors:</b> Bharath Muppasani, Vishal Pallagani, Kausik Lakkaraju, Shuge Lei, Biplav Srivastava, Brett Robertson, Andrea Hickerson, Vignesh Narayanan
                <br><b>Summary:</b>
                <br>We created chatbots to help increase voting among seniors 
                and first-time voters by giving them easy access to trusted election information tailored 
                to their needs. Our system, built on the Rasa platform, ensures the information is reliable 
                and allows for quick chatbot setup for any region. We've tested these chatbots in two 
                US states where voting has been difficult, focusing on groups of senior citizens. 
                This project aims to support voters and democracy by making accurate election information more accessible.
                <br><b>Publication Type:</b> <span class="publication-type">Workshop</span>
                <br><b>Venue:</b> <span class="venue-name">AAAI Workshop on AI for Credible Elections</span>
                <br><a href="https://onlinelibrary.wiley.com/doi/epdf/10.1002/aaai.12109"><b>Paper</b></a>
                |<a href="../bibs/2023_ai4ce.txt"><b>Bibtex</b></a>
            </p>
    </div>

    <div class="year-section">
        <h3 class="year">2022</h3>
        <p>
            <b class="pub-title">Why is my System Biased?: Rating of AI Systems through a Causal Lens</b>
            <br><b>Authors:</b> Kausik Lakkaraju
            <br><b>Summary:</b>
            <br>This is a student paper which formulates my PhD dissertation problem and gives an overview of the solution. 
            Idea is to evaluate / rate AI systems for bias using causal analysis.
            <br><b>Publication Type:</b> <span class="publication-type">Doctoral Consortium</span>
            <br><b>Venue:</b> <span class="venue-name">AIES</span>
            <br><a href="https://doi.org/10.1145/3514094.3539556"><b>Paper</b></a>
            |<a href="../bibs/2022_student_aies.txt"><b>Bibtex</b></a>
        </p>

        <p>
            <b class="pub-title">ALLURE: A Multi-Modal Guided Environment for Helping Children Learn to Solve a Rubik’s Cube with Automatic Solving and Interactive Explanations</b>
            <br><b>Authors:</b> Kausik Lakkaraju, Thahimum Hassan, Vedant Khandelwal, Prathamjeet Singh, Cassidy Bradley, Ronak Shah, Forest Agostinelli, Biplav Srivastava, Dezhi Wu
            <br><b>Summary:</b>
            <br>ALLURE is a Deep Reinforcement Learning based, multi-modal, explainable chatbot which teaches
            children how to solve a Rubik’s Cube and allows the children to interact with the multi-modal chatbot while trying to solve the Cube.
            <br><b>Publication Type:</b> <span class="publication-type">Demonstration</span>
            <br><b>Venue:</b> <span class="venue-name">AAAI</span>
            <br><a href="https://ojs.aaai.org/index.php/AAAI/article/view/21722"><b>Paper</b></a>
            |<a href="../bibs/2022_allure.txt"><b>Bibtex</b></a>
            |<a href="https://youtu.be/-0aKDVoEGvs"><b>Video</b></a>

        </p>

        <p>
            <b class="pub-title">Data-Based Insights for the Masses: Scaling Natural Language Querying to Middleware Data</b>
            <br><b>Authors:</b> Lakkaraju Kausik, Palaiya Vinamra, Paladi Sai Teja, Appajigowda Chinmayi, Srivastava Biplav, Johri Lokesh
            <br><b>Summary:</b>
            <br>This is a demonstration paper which talks about a RASA-based chatbot that allows users to control
            their network usage and bandwith using smart routers in a household or office setting. We also demonstrated another chatbot in the same paper which helps users in monitoring the power usage in a house, office or university setting using 
            smart sensors. These were deployed on Alexa device and Web for demonstration.
            <br><b>Publication Type:</b> <span class="publication-type">Demonstration</span>
            <br><b>Venue:</b> <span class="venue-name">DASFAA</span>
            <br><a href="https://doi.org/10.1007/978-3-031-00129-1_49"><b>Paper</b></a>
            |<a href="../bibs/2022_dasfaa.txt"><b>Bibtex</b></a>
            |<a href="https://vimeo.com/651270271"><b>Video</b></a>

        </p>

        <p>
            <b class="pub-title">A Rich Recipe Representation as Plan to Support Expressive Multi-Modal Queries on Recipe Content and Preparation Process.</b>
            <br><b>Authors:</b> Vishal Pallagani, Priyadharsini Ramamurthy, Vedant Khandelwal, Revathy Venkataramanan, Kausik Lakkaraju, Sathyanarayanan N Aakur, Biplav Srivastava
            <br><b>Summary:</b>
            <br>In this paper, we discussed the construction of machine-understandable 
            rich recipe representation (R3), in the form of plans, from the recipes available in natural language. R3 is infused with additional knowledge like allergens and possible failures at each cooking step. 
            <br><b>Publication Type:</b> <span class="publication-type">Workshop</span>
            <br><b>Venue:</b> <span class="venue-name">ICAPS Workshop on Knowledge Engineering for Planning and Scheduling</span>
            <br><a href="http://icaps22.icaps-conference.org/workshops/KEPS/KEPS-22_paper_4286.pdf"><b>Paper</b></a>
            |<a href="../bibs/2022_r3_keps.txt"><b>Bibtex</b></a>
            |<a href="https://youtu.be/-CPqxmAo2kk"><b>Video</b></a>

        </p>

        <p>
            <b class="pub-title">Explainable Pathfinding for Inscrutable Planners with Inductive Logic Programming</b>
            <br><b>Authors:</b> Rojina Panta, Forest Agostinelli, Vedant Khandelwal, Biplav Srivastava, Bharath Chandra Muppasani, Kausik Lakkaraju, Dezhi Wu
            <br><b>Summary:</b>
            <br>By combining inductive logic programming (ILP) with a given inscrutable planner, we constructed an explainable graph representing solutions to all states in the state space. 
            This graph can then be summarized using a variety of methods such as hierarchical representations or simple if/else rules. 
            We tested our approach on Towers of Hanoi.
            <br><b>Publication Type:</b> <span class="publication-type">Workshop</span>
            <br><b>Venue:</b> <span class="venue-name">ICAPS Workshop on Explainable AI Planning</span>
            <br><a href="https://openreview.net/forum?id=S44aSPW6lRa"><b>Paper</b></a>
            |<a href="../bibs/2022_xai_ilp.txt"><b>Bibtex</b></a>
            |<a href="https://openreview.net/forum?id=S44aSPW6lRa"><b>Video</b></a>

        </p>

        <p>
            <b class="pub-title">ROSE: Tool and Data ResOurces to Explore the Instability of SEntiment Analysis Systems</b>
            <br><b>Authors:</b> Gaurav Mundada, Kausik Lakkaraju, Biplav Srivastava
            <br><b>Summary:</b>
            <br>ROSE is a tool that helps examine gender bias in Sentiment Analysis Systems (SASs), which score text for sentiment and emotion. 
                It offers a dataset of text inputs with their sentiment scores and a visualization tool for analyzing SAS behavior towards gender. 
                Developed with d3.js, ROSE is freely accessible for public use. 
                <br><b>Publication Type:</b> <span class="publication-type">Unpublished Manuscript</span>
                <br><a href="https://www.researchgate.net/profile/Biplav-Srivastava/publication/358475224_ROSE_Tool_and_Data_ResOurces_to_Explore_the_Instability_of_SEntiment_Analysis_Systems/links/6203f8d0c83d2b75dffd6ecc/ROSE-Tool-and-Data-ResOurces-to-Explore-the-Instability-of-SEntiment-Analysis-Systems.pdf"><b>Paper</b></a>
            |<a href="../bibs/2022_rose.txt" target="_blank" type="text/plain"><b>BibTex</b></a>
            |<a href="https://ai4society.github.io/sentiment-rating/"><b>Tool</b></a>

        </p>
    </div>
</div>

<div class="category-title">Patents</div>
<div class="year-section">
    <h3 class="year">2025</h3>
    <p>
        <b class="pub-title">Multimodal retrieval and execution monitoring using rich recipe representation</b>
        <br><b>Inventors:</b> Biplav Srivastava, Vishal Pallagani, Revathy Chandrasekaran Venka, Vedant Khandelwal, Kausik Lakkaraju
        <br><b>Summary:</b>
        <br>This work introduces a Rich Recipe Representation (R3) to improve how machines 
            interpret and retrieve complex workflows like recipes. By enriching each step with 
            contextual knowledge, such as allergen risks, failure modes, 
            and solutions, R3 enables more accurate reasoning and retrieval. 
            It powers a web-based system that supports multi-modal queries and real-time 
            agent monitoring during task execution.
            <br><b>Publication Type:</b> <span class="publication-type">Patent</span>
            <br><a href="https://patents.google.com/patent/US12332873B2/en"><b>Patent Link</b></a>
        |<a href="../bibs/2025_patent_recipe.txt" target="_blank" type="text/plain"><b>BibTex</b></a>
    </p>
</div>
<div class="year-section">
    <h3 class="year">2024</h3>
    <p>
        <b class="pub-title">Robust useful and general task-oriented virtual assistants</b>
        <br><b>Inventors:</b> Biplav Srivastava, Kausik Lakkaraju, Revathy Venkataramanan, Vishal Pallagani, Vedant Khandelwal, Hong Yung Yip
        <br><b>Summary:</b>
        <br>This work presents a framework for task-oriented virtual assistants that combine 
        open-world knowledge discovery, user personalization, and domain-specific adaptation. 
        Designed for procedural tasks like cooking or DIY, the system also supports fault-tolerant 
        content curation for task completion despite common errors.
        <br><b>Publication Type:</b> <span class="publication-type">Patent</span>
        <br><a href="https://patents.google.com/patent/US12067983B2/en"><b>Patent Link</b></a>
        |<a href="../bibs/2024_patent_recipe.txt" target="_blank" type="text/plain"><b>BibTex</b></a>
    </p>
        <p>
        <b class="pub-title">Assigning trust rating to ai services using causal impact analysis</b>
        <br><b>Inventors:</b>Biplav Srivastava, Kausik Lakkaraju, Marco Valtorta
        <br><b>Summary:</b>
        <br>This work proposes a causal rating framework to assess the trustability of Sentiment Analysis
        Systems (SASs) based on the influence of inputs like gender, race, and emotion-laden words. 
        The method assigns both fine-grained and overall ratings using a causal lens, and 
        includes an implementation across five SASs, deep learning, lexicon-based, 
        and custom models, to help users interpret model behavior in practical settings.
        <br><b>Publication Type:</b> <span class="publication-type">Patent</span>
        <br><a href="https://patents.google.com/patent/US20240062079A1/en"><b>Patent Link</b></a>
        |<a href="../bibs/2025_patent_rating.txt" target="_blank" type="text/plain"><b>BibTex</b></a>
    </p>
</div>
<!-- <div class="year-section">
    <h3 class="year">2023</h3>
</div>
<div class="year-section">
    <h3 class="year">2022</h3>
</div> -->
</div>

</body>
</html>
